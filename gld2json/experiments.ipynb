{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from parsers import parse_gld_xls, slugify_language, parse_notes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parsed = parse_gld_xls('test_data/hai.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLD_IPA_MAP_RAW = '''ɳʘ,ʘ̃\n",
    "ɳǀ,ǀ̃\n",
    "ɳǂ,ǂ̃\n",
    "ɳǃ,ǃ̃\n",
    "ɳǃǃ,‼̃\n",
    "ɳǁ,ǁ̃\n",
    "ʘ̰,ʘ̬\n",
    "ɡʘ,ʘ̬\n",
    "ǀ̰,ǀ̬\n",
    "ɡǀ,ǀ̬\n",
    "ǂ̰,ǂ̬\n",
    "ɡǂ,ǂ̬\n",
    "ǃ̰,ǃ̬\n",
    "ɡǃ,ǃ̬\n",
    "ǃǃ̰,‼̬\n",
    "ɡǃǃ,‼̬\n",
    "ǁ̰,ǁ̬\n",
    "ɡǁ,ǁ̬\n",
    "ǃǃ,‼\n",
    "pᶠ,p͡ɸ\n",
    "bᵛ,b͡β\n",
    "p̪ᶠ,p̪͡f\n",
    "b̪ᵛ,b̪͡v\n",
    "tᶿ,t̪͡θ\n",
    "dᶞ,d̪͡ð\n",
    "tʳ,t͡ɹ̝̊\n",
    "dʳ,d͡ɹ̝\n",
    "kˣ,k͡x\n",
    "gˠ,g͡ɣ\n",
    "qᵡ,q͡χ\n",
    "ɢʶ,ɢ͡ʁ\n",
    "ʡʢ,ʡ͡ʢ\n",
    "ʔh,ʔ͡h\n",
    "c,t͡s\n",
    "ʒ,d͡z\n",
    "č,t̠͡ʃ\n",
    "ǯ,d̠͡ʒ\n",
    "c̢,ʈ͡ʂ\n",
    "ᶚ,ɖ͡ʐ\n",
    "ɕ,t͡ɕ\n",
    "ʓ,d͡ʑ\n",
    "ƛ,tɬ\n",
    "ᴌ,dɮ\n",
    "m,m\n",
    "ɱ,ɱ\n",
    "n,n\n",
    "ɳ,ɳ\n",
    "ɲ,ɲ\n",
    "ŋ,ŋ\n",
    "ɴ,ɴ\n",
    "p,p\n",
    "b,b\n",
    "p̪,p̪\n",
    "t,t\n",
    "d,d\n",
    "ʈ,ʈ\n",
    "ɖ,ɖ\n",
    "ȶ,c\n",
    "ȡ,ɟ\n",
    "k,k\n",
    "g,g\n",
    "q,q\n",
    "ɢ,ɢ\n",
    "ʡ,ʡ\n",
    "ʔ,ʔ\n",
    "ɂ,ʔ\n",
    "Ɂ,ʔ\n",
    "ˀ,ʔ\n",
    "ɓ,ɓ\n",
    "ɗ,ɗ\n",
    "ʄ,ʄ\n",
    "ɠ,ɠ\n",
    "ʛ,ʛ\n",
    "ɸ,ɸ\n",
    "β,β\n",
    "ꞵ,β\n",
    "f,f\n",
    "v,v\n",
    "θ,θ\n",
    "ð,ð\n",
    "s,s\n",
    "z,z\n",
    "š,ʃ\n",
    "ž,ʒ\n",
    "ʂ,ʂ\n",
    "ʐ,ʐ\n",
    "ʆ,ɕ\n",
    ",ɕ\n",
    "ʑ,ʑ\n",
    "x,x\n",
    "ɣ,ɣ\n",
    "γ,ɣ\n",
    "χ,χ\n",
    "ꭓ,χ\n",
    "ʁ,ʁ\n",
    "ħ,ħ\n",
    "ʕ,ʕ\n",
    "ˁ,ʕ\n",
    "ʜ,ʜ\n",
    "ʢ,ʢ\n",
    "h,h\n",
    "ɦ,ɦ\n",
    "ʍ,ʍ\n",
    "w,w\n",
    "ɹ,ɹ\n",
    "ɻ,ɻ\n",
    "y,j\n",
    "ɰ,ɰ\n",
    "r,r\n",
    "ʀ,ʀ\n",
    "ⱱ,ⱱ\n",
    "ɾ,ɾ\n",
    "ɽ,ɽ\n",
    "ɢ̆,ɢ̆\n",
    "ɬ,ɬ\n",
    "ʫ,ɮ\n",
    "l,l\n",
    "ɭ,ɭ\n",
    "ʎ,ʎ\n",
    "ɫ,ɫ\n",
    "ʘ,ʘ\n",
    "ǀ,ǀ\n",
    "ǂ,ǂ\n",
    "ǃ,ǃ\n",
    "ǁ,ǁ\n",
    "i,i\n",
    "ü,y\n",
    "ɨ,ɨ\n",
    "ʉ,ʉ\n",
    "ɯ,ɯ\n",
    "u,u\n",
    "ɪ,ɪ\n",
    "ʏ,ʏ\n",
    "ʊ,ʊ\n",
    "e,e\n",
    "ö,ø\n",
    "ɘ,ɘ\n",
    "ɵ,ɵ\n",
    "ɤ,ɤ\n",
    "o,o\n",
    "ǝ,ə\n",
    "ə,ə\n",
    "ɛ,ɛ\n",
    "œ,œ\n",
    "ɜ,ɜ\n",
    "ɞ,ɞ\n",
    "ʌ,ʌ\n",
    "ɔ,ɔ\n",
    "ä,æ\n",
    "ɐ,ɐ\n",
    "a,a\n",
    "ɑ,ɑ\n",
    "ɒ,ɒ\n",
    "◌̥,◌̥\n",
    "◌̊,◌̊\n",
    "◌̪,◌̪\n",
    "◌̬,◌̬\n",
    "ʰ,ʰ\n",
    "ʱ,ʱ\n",
    "◌̹,◌̹\n",
    "◌͗,◌͗\n",
    "◌˒,◌˒\n",
    "◌̜,◌̜\n",
    "◌͑,◌͑\n",
    "◌˓,◌˓\n",
    "◌̟,◌̟\n",
    "◌˖,◌˖\n",
    "◌̠,◌̠\n",
    "◌˗,◌˗\n",
    "◌̽,◌̽\n",
    "◌̩,◌̩\n",
    "◌̍,◌̍\n",
    "◌̯,◌̯\n",
    "◌̑,◌̑\n",
    "◌˞,◌˞\n",
    "◌ʳ,◌˞\n",
    "◌̤,◌̤\n",
    "◌̰,◌̰\n",
    "◌̼,◌̼\n",
    "ʷ,ʷ\n",
    "ʸ,ʲ\n",
    "◌ˠ,◌ˠ\n",
    "◌ˤ,◌ˤ\n",
    "◌̴,◌̴\n",
    "◌̝,◌̝\n",
    "◌˔,◌˔\n",
    "◌̞,◌̞\n",
    "◌˕,◌˕\n",
    "◌̘,◌̘\n",
    "◌̙,◌̙\n",
    "◌̪,◌̪\n",
    "◌͆,◌͆\n",
    "◌̺,◌̺\n",
    "◌̻,◌̻\n",
    "◌̃,◌̃\n",
    "ⁿ,ⁿ\n",
    "ˡ,ˡ\n",
    "◌̚,◌̚\n",
    "ᵊ,ᵊ\n",
    "ᶿ,ᶿ\n",
    "ˣ,ˣ\n",
    "ʼ,ʼ\n",
    "◌͡◌,◌͡◌\n",
    "◌͜◌,◌͜◌\n",
    "ˈ,ˈ\n",
    "ˌ,ˌ\n",
    "ː,ː\n",
    "ˑ,ˑ\n",
    "◌̆,◌̆\n",
    "|,|\n",
    "‖,‖\n",
    ".,.\n",
    "‿,‿\n",
    "◌̋,◌̋\n",
    "˥,˥\n",
    "◌́,◌́\n",
    "˦,˦\n",
    "◌̄,◌̄\n",
    "˧,˧\n",
    "◌̀,◌̀\n",
    "˨,˨\n",
    "◌̏,◌̏\n",
    "˩,˩\n",
    "ꜜ,ꜜ\n",
    "ꜛ,ꜛ\n",
    "◌̌,◌̌\n",
    "˩˥,˩˥\n",
    "◌̂,◌̂\n",
    "˥˩,˥˩\n",
    "◌᷄,◌᷄\n",
    "˦˥,˦˥\n",
    "◌᷅,◌᷅\n",
    "˩˨,˩˨\n",
    "◌᷈,◌᷈\n",
    "˧˦˧,˧˦˧\n",
    "↗,↗\n",
    "↘,↘\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɳʘ,ʘ̃\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "for o in io.StringIO(GLD_IPA_MAP_RAW):\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "GLD_IPA_MAP = [(gld.replace(\"◌\", \"\"), ipa.replace(\"◌\", \"\"))\n",
    "               for gld, ipa in csv.reader(open('gld_ipa.csv'))]\n",
    "SORTED_GLD_TO_IPA = sorted(GLD_IPA_MAP, reverse=True)\n",
    "RE_KEEP = re.compile(r\"^[- ~*=()/,A-Z]\")\n",
    "\n",
    "\n",
    "def to_ipa(s: str) -> str:\n",
    "    result = []\n",
    "    while s:\n",
    "        if RE_KEEP.match(s):\n",
    "            gld = s[:1]\n",
    "            ipa = gld\n",
    "        else:\n",
    "            gld, ipa = next(((gld, ipa) for gld, ipa in SORTED_GLD_TO_IPA if s.startswith(gld)),\n",
    "                            (None, None))\n",
    "        if gld:\n",
    "            result.append(ipa)\n",
    "            s = s[len(gld):]\n",
    "        else:\n",
    "            # Try to decompose the first character\n",
    "            c = unicodedata.normalize('NFD', s[:1])\n",
    "            if c == s[:1]:\n",
    "                # print(\"{}: Unknown character U+{:04X} at '{}...'\".format(context, ord(s[:1]), s[:20]))\n",
    "                result.append(s[:1])\n",
    "                s = s[1:]\n",
    "            else:\n",
    "                s = c + s[1:]\n",
    "    return ''.join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'r' == 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, Number                                                                  1\n",
      "South Haida (Skidegate)                                               an\n",
      "South Haida (Skidegate) #                                               1\n",
      "North Haida (Masset)                                            han ~ .an\n",
      "North Haida (Masset) #                                                  1\n",
      "South Haida (Skidegate) notes                    Enrico 2005: 1551, 1884.\n",
      "North Haida (Masset) notes       Enrico 2005: 1551, 1884. A <i>(h)án</i>.\n",
      "Word                                                                  all\n",
      "Common Haida notes                                                    NaN\n",
      "Name: 1, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "rows = df.iterrows()\n",
    "next(rows)\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'languages': {'SouthHaidaSkidegate': {'author': 'A. Kassian',\n",
       "   'sources': ['Enrico2003', 'Enrico2005'],\n",
       "   'ethnologue': 'hax',\n",
       "   'name': 'South Haida (Skidegate)'},\n",
       "  'NorthHaidaMasset': {'author': 'A. Kassian',\n",
       "   'sources': ['Enrico2003', 'Enrico2005'],\n",
       "   'ethnologue': 'hdn',\n",
       "   'name': 'North Haida (Masset)'}},\n",
       " 'sources': {'Enrico2003': {}, 'Enrico2005': {}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SouthHaidaSkidegate': {'author': 'A. Kassian',\n",
       "  'sources': ['Enrico2003', 'Enrico2005'],\n",
       "  'ethnologue': 'hax',\n",
       "  'name': 'South Haida (Skidegate)'},\n",
       " 'NorthHaidaMasset': {'author': 'A. Kassian',\n",
       "  'sources': ['Enrico2003', 'Enrico2005'],\n",
       "  'ethnologue': 'hdn',\n",
       "  'name': 'North Haida (Masset)'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed['languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Enrico2003', 'Enrico2005'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed['sources'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = []\n",
    "aux_col_suffixes = (' #', ' notes', ' etymology')\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx > 0:\n",
    "        for colname, value in row.items():\n",
    "            if not any(colname.endswith(suffix) for suffix in aux_col_suffixes) and slugify_language(colname) in parsed['languages']:\n",
    "                forms.append({\n",
    "                    'Language_ID': slugify_language(colname),\n",
    "                    'Parameter': row['Word'],\n",
    "                    'Form': value,\n",
    "                    'Comment': row[colname + ' notes'],\n",
    "                    'Segments': ''\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-26 21:48:56,667]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,667]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,667]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,667]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,670]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,670]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,670]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,670]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,672]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,672]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,672]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,672]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,675]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,675]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,675]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n",
      "[2019-08-26 21:48:56,675]  WARNING: treating 'I' in: \"Enrico 2003: I, 219\" as volume number.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      ([{'ref': 'Enrico2005', 'pages': [1551, 1884]}...\n",
       "1      ([{'ref': 'Enrico2005', 'pages': [1551, 1884]}...\n",
       "2      ([{'ref': 'Enrico2005', 'pages': [1305, 1888]}...\n",
       "3      ([{'ref': 'Enrico2005', 'pages': [1305, 1888]}...\n",
       "4      ([{'ref': 'Enrico2005', 'pages': [1495, 1892]}...\n",
       "                             ...                        \n",
       "225    ([{'ref': 'Enrico2005', 'pages': [297, 2112]}]...\n",
       "226    ([{'ref': 'Enrico2005', 'pages': [556, 2114]}], )\n",
       "227    ([{'ref': 'Enrico2005', 'pages': [556, 2114]}]...\n",
       "228    ([{'ref': 'Enrico2005', 'pages': [110, 2116]}], )\n",
       "229    ([{'ref': 'Enrico2005', 'pages': [110, 2116]}]...\n",
       "Name: Comment, Length: 230, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "_parse_notes = partial(parse_notes, unique_sources=set(parsed['sources'].keys()))\n",
    "\n",
    "df['Comment'].apply(_parse_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
